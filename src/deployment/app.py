"""
Flask application for serving the Heart Disease Prediction model.

This application loads a pre-trained machine learning model and a preprocessor
from artifacts generated by the training pipeline (tracked with MLflow and stored locally).
It exposes a `/predict` endpoint that accepts raw patient data in JSON format,
preprocesses this data using the loaded preprocessor, and returns predictions
from the model.

The application includes:
- Initialization of the Flask app.
- A global error handler for HTTPExceptions to ensure JSON responses for errors.
- Loading of the best model (identified by `data/best_model_info.json`) and
  the preprocessor (`data/preprocessor.joblib`) on startup.
- A root endpoint `/` for health checks/status.
- A `/predict` endpoint for making predictions. This endpoint handles:
    - JSON input validation.
    - Dataframe creation from input, ensuring correct feature order and handling
      of missing columns (by filling with NaN before preprocessing).
    - Application of the loaded preprocessor.
    - Prediction using the loaded MLflow model.
    - JSON serialization of predictions.
    - Error handling for various scenarios (file not found, invalid input, etc.).

To run for development: `python src/deployment/app.py`
To run with Gunicorn (example): `gunicorn --bind 0.0.0.0:5001 src.deployment.app:app`
(Assumes MLFLOW_TRACKING_URI is set or defaults to local `./mlruns`, and artifacts are present)
"""
import os
import flask
from flask import Flask, request, jsonify
from werkzeug.exceptions import HTTPException # Import HTTPException
import mlflow
import pandas as pd
import joblib
import json
import numpy as np # Will be needed for NaN representation if any

# Initialize Flask app
app = Flask(__name__)

# --- Global Error Handler for HTTPExceptions ---
@app.errorhandler(HTTPException)
def handle_exception(e):
    """Return JSON instead of HTML for HTTP errors."""
    response = e.get_response()
    response.data = json.dumps({
        "code": e.code,
        "name": e.name,
        "description": e.description,
    })
    response.content_type = "application/json"
    return response

# --- Configuration ---
BEST_MODEL_INFO_PATH = "data/best_model_info.json"
PREPROCESSOR_PATH = "data/preprocessor.joblib"
MODEL = None
PREPROCESSOR = None

# Define the order of columns expected by the preprocessor (must match training)
# These are the columns of X in preprocess_data.py before ColumnTransformer
EXPECTED_RAW_FEATURE_COLUMNS = [
    "age", "sex", "cp", "trestbps", "chol", "fbs", "restecg",
    "thalach", "exang", "oldpeak", "slope", "ca", "thal"
]

def load_model_and_preprocessor():
    """Loads the best ML model and preprocessor."""
    global MODEL, PREPROCESSOR

    app.logger.info("Loading model and preprocessor...")
    # Load best model URI from the info file
    if not os.path.exists(BEST_MODEL_INFO_PATH):
        app.logger.error(f"{BEST_MODEL_INFO_PATH} not found. Run evaluation script first.")
        raise FileNotFoundError(f"{BEST_MODEL_INFO_PATH} not found.")

    with open(BEST_MODEL_INFO_PATH, 'r') as f:
        model_info = json.load(f)
    model_uri = model_info.get("model_uri")
    if not model_uri:
        app.logger.error("Model URI not found in best_model_info.json.")
        raise ValueError("Model URI not found.")

    app.logger.info(f"Loading model from URI: {model_uri}")
    MODEL = mlflow.pyfunc.load_model(model_uri) # Generic MLflow model loading
    app.logger.info("Model loaded successfully.")

    # Load preprocessor
    if not os.path.exists(PREPROCESSOR_PATH):
        app.logger.error(f"{PREPROCESSOR_PATH} not found. Run preprocessing script to generate it.")
        raise FileNotFoundError(f"{PREPROCESSOR_PATH} not found.")

    PREPROCESSOR = joblib.load(PREPROCESSOR_PATH)
    app.logger.info("Preprocessor loaded successfully.")

# --- Routes ---
@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "message": "Heart Disease Prediction API is running.",
        "model_status": "Loaded" if MODEL else "Not loaded",
        "preprocessor_status": "Loaded" if PREPROCESSOR else "Not loaded"
    })

@app.route("/predict", methods=["POST"])
def predict():
    if MODEL is None or PREPROCESSOR is None:
        return jsonify({"error": "Model or preprocessor not loaded. Check server logs."}), 500

    try:
        input_data = request.get_json()
        if not input_data:
            return jsonify({"error": "No input data provided."}), 400

        # Convert input JSON to DataFrame - expecting a single record or list of records
        if isinstance(input_data, dict): # Single record
            input_df_raw = pd.DataFrame([input_data])
        elif isinstance(input_data, list): # Batch of records
            input_df_raw = pd.DataFrame(input_data)
        else:
            return jsonify({"error": "Input data must be a JSON object or a list of JSON objects."}), 400

        # Ensure all expected columns are present and in the correct order
        # Handle missing columns by adding them with NaN (or a suitable default if appropriate)
        for col in EXPECTED_RAW_FEATURE_COLUMNS:
            if col not in input_df_raw.columns:
                input_df_raw[col] = np.nan # Or some other default. Preprocessor should handle NaNs if trained to.

        # Reorder columns to match the training order for the preprocessor
        input_df_raw = input_df_raw[EXPECTED_RAW_FEATURE_COLUMNS]

        app.logger.info(f"Raw input DataFrame columns: {input_df_raw.columns.tolist()}")
        app.logger.info(f"Raw input DataFrame head:\n{input_df_raw.head()}")


        # Apply preprocessing
        # The preprocessor (ColumnTransformer) expects a DataFrame with the original feature names
        processed_input_data = PREPROCESSOR.transform(input_df_raw)
        app.logger.info(f"Processed input data shape: {processed_input_data.shape}")

        # Note: PREPROCESSOR.transform might return a NumPy array.
        # The MLflow pyfunc model's predict method can usually handle this,
        # but if it strictly needs a DataFrame with feature names, this needs adjustment.
        # The `train_X.csv` has feature names after one-hot encoding.
        # However, `mlflow.pyfunc.load_model` with scikit-learn often handles array inputs correctly.

        # Make predictions
        predictions = MODEL.predict(processed_input_data)

        # Ensure predictions are JSON serializable (e.g. convert numpy types to native Python types)
        if isinstance(predictions, np.ndarray):
            predictions_list = predictions.tolist()
        else:
            predictions_list = list(predictions) # Assuming it's some other iterable

        return jsonify({"predictions": predictions_list})

    except FileNotFoundError as e:
        app.logger.error(f"File not found error during prediction: {e}")
        return jsonify({"error": f"A required file was not found: {e.filename}. Ensure all artifacts are in place."}), 500
    except ValueError as e:
        app.logger.error(f"Value error during prediction: {e}")
        return jsonify({"error": f"Invalid input or data format: {str(e)}"}), 400
    except HTTPException as e:
        # Re-raise the HTTPException so that the @app.errorhandler can catch it
        # and format it as a JSON response.
        raise e
    except Exception as e:
        app.logger.error(f"An unexpected error occurred during prediction: {e}", exc_info=True)
        return jsonify({"error": f"An unexpected error occurred: {str(e)}"}), 500

if __name__ == "__main__":
    # Set MLFLOW_TRACKING_URI if not already set (useful for local testing)
    # In production, this would typically be managed by the environment.
    os.environ.setdefault("MLFLOW_TRACKING_URI", "./mlruns")

    try:
        load_model_and_preprocessor()
    except Exception as e:
        app.logger.error(f"Failed to load model or preprocessor on startup: {e}", exc_info=True)
        # Depending on severity, you might choose to exit or let Flask start and handle errors at request time.

    # For development server:
    app.run(host="0.0.0.0", port=5001, debug=True)
    # For a more production-like setup, use gunicorn, e.g.:
    # gunicorn --bind 0.0.0.0:5001 src.deployment.app:app
    # The FLASK_APP env var is more for the 'flask run' command.
    # When using gunicorn, you specify the app module and instance directly.
